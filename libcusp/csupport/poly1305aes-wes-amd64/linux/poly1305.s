.text
.p2align 5
.globl _poly1305_amd64
.globl poly1305_amd64
_poly1305_amd64:
poly1305_amd64:
mov %rsp,%r11
lea poly1305_amd64_constants(%rip),%r10
sub %r10,%r11
and $4095,%r11
add $192,%r11
sub %r11,%rsp
movq %r11,32(%rsp)
movq %r12,40(%rsp)
movq %r13,48(%rsp)
movq %r14,56(%rsp)
movq %r15,64(%rsp)
movq %rbx,72(%rsp)
movq %rbp,80(%rsp)
mov  %rdi,%r9
fldcw poly1305_amd64_rounding(%rip)
mov  %rsi,%rdi
fildl 0(%rdi)
fstpl 88(%rsp)
fildl 4(%rdi)
fmull poly1305_amd64_two32(%rip)
fstl 96(%rsp)
fmull poly1305_amd64_scale(%rip)
fstpl 104(%rsp)
fildl 8(%rdi)
fmull poly1305_amd64_two64(%rip)
fstl 112(%rsp)
fmull poly1305_amd64_scale(%rip)
fstpl 120(%rsp)
fildl 12(%rdi)
fmull poly1305_amd64_two96(%rip)
fstl 128(%rsp)
fmull poly1305_amd64_scale(%rip)
fstpl 136(%rsp)
fldz
fldz
fldz
fldz
movl  $0x43300000,148(%rsp)
movl  $0x45300000,156(%rsp)
movl  $0x47300000,164(%rsp)
movl  $0x49300000,172(%rsp)
mov  %rcx,%rsi
mov  %r8,%rcx
cmp  $16,%rcx
jb ._addatmost15bytes
movl   12(%rsi),%edi
movl   8(%rsi),%r8d
movl   4(%rsi),%eax
movl   0(%rsi),%r10d
movl %edi,168(%rsp)
movl %r8d,160(%rsp)
movl %eax,152(%rsp)
movl %r10d,144(%rsp)
add  $16,%rsi
sub  $16,%rcx
fxch %st(3)
faddl 168(%rsp)
fsubl poly1305_amd64_doffset3minustwo128(%rip)
fxch %st(2)
faddl 160(%rsp)
fsubl poly1305_amd64_doffset2(%rip)
fxch %st(1)
faddl 152(%rsp)
fsubl poly1305_amd64_doffset1(%rip)
fxch %st(3)
faddl 144(%rsp)
fsubl poly1305_amd64_doffset0(%rip)
cmp  $16,%rcx
jb ._multiplyaddatmost15bytes
._multiplyaddatleast16bytes:
movl   12(%rsi),%edi
movl   8(%rsi),%r8d
movl   4(%rsi),%eax
movl   0(%rsi),%r10d
movl %edi,168(%rsp)
movl %r8d,160(%rsp)
movl %eax,152(%rsp)
movl %r10d,144(%rsp)
add  $16,%rsi
sub  $16,%rcx
fldl poly1305_amd64_alpha130(%rip)
fadd %st(3),%st(0)
fsubl poly1305_amd64_alpha130(%rip)
fsubr %st(0),%st(3)
fmull poly1305_amd64_scale(%rip)
fldl poly1305_amd64_alpha32(%rip)
fadd %st(2),%st(0)
fsubl poly1305_amd64_alpha32(%rip)
fsubr %st(0),%st(2)
fxch %st(2)
faddp %st(0),%st(1)
fldl poly1305_amd64_alpha64(%rip)
fadd %st(5),%st(0)
fsubl poly1305_amd64_alpha64(%rip)
fsubr %st(0),%st(5)
fldl poly1305_amd64_alpha96(%rip)
fadd %st(4),%st(0)
fsubl poly1305_amd64_alpha96(%rip)
fsubr %st(0),%st(4)
fxch %st(4)
faddp %st(0),%st(1)
fxch %st(4)
faddp %st(0),%st(3)
fxch %st(4)
faddp %st(0),%st(1)
fldl 128(%rsp)
fmul %st(4),%st(0)
fldl 112(%rsp)
fmul %st(5),%st(0)
fldl 96(%rsp)
fmul %st(6),%st(0)
fldl 88(%rsp)
fmulp %st(0),%st(7)
fldl 112(%rsp)
fmul %st(4),%st(0)
faddp %st(0),%st(3)
fldl 96(%rsp)
fmul %st(4),%st(0)
faddp %st(0),%st(2)
fldl 88(%rsp)
fmul %st(4),%st(0)
faddp %st(0),%st(1)
fldl 136(%rsp)
fmulp %st(0),%st(4)
fxch %st(3)
faddp %st(0),%st(6)
fldl 96(%rsp)
fmul %st(5),%st(0)
faddp %st(0),%st(2)
fldl 88(%rsp)
fmul %st(5),%st(0)
faddp %st(0),%st(1)
fldl 136(%rsp)
fmul %st(5),%st(0)
faddp %st(0),%st(3)
fldl 120(%rsp)
fmulp %st(0),%st(5)
fxch %st(4)
faddp %st(0),%st(5)
fldl 88(%rsp)
fmul %st(3),%st(0)
faddp %st(0),%st(1)
fldl 136(%rsp)
fmul %st(3),%st(0)
faddp %st(0),%st(4)
fldl 120(%rsp)
fmul %st(3),%st(0)
faddp %st(0),%st(2)
fxch %st(3)
fldl 104(%rsp)
fmulp %st(0),%st(3)
fxch %st(2)
faddp %st(0),%st(4)
cmp  $16,%rcx
fldl 168(%rsp)
fsubl poly1305_amd64_doffset3minustwo128(%rip)
faddp %st(0),%st(3)
fldl 160(%rsp)
fsubl poly1305_amd64_doffset2(%rip)
faddp %st(0),%st(2)
fldl 152(%rsp)
fsubl poly1305_amd64_doffset1(%rip)
faddp %st(0),%st(1)
fxch %st(3)
fldl 144(%rsp)
fsubl poly1305_amd64_doffset0(%rip)
faddp %st(0),%st(1)
jae ._multiplyaddatleast16bytes
._multiplyaddatmost15bytes:
fldl poly1305_amd64_alpha130(%rip)
fadd %st(3),%st(0)
fsubl poly1305_amd64_alpha130(%rip)
fsubr %st(0),%st(3)
fmull poly1305_amd64_scale(%rip)
fldl poly1305_amd64_alpha32(%rip)
fadd %st(2),%st(0)
fsubl poly1305_amd64_alpha32(%rip)
fsubr %st(0),%st(2)
fldl poly1305_amd64_alpha64(%rip)
fadd %st(6),%st(0)
fsubl poly1305_amd64_alpha64(%rip)
fsubr %st(0),%st(6)
fldl poly1305_amd64_alpha96(%rip)
fadd %st(5),%st(0)
fsubl poly1305_amd64_alpha96(%rip)
fsubr %st(0),%st(5)
fxch %st(4)
faddp %st(0),%st(3)
fxch %st(6)
faddp %st(0),%st(1)
fxch %st(3)
faddp %st(0),%st(5)
fxch %st(3)
faddp %st(0),%st(1)
fldl 128(%rsp)
fmul %st(3),%st(0)
fldl 112(%rsp)
fmul %st(4),%st(0)
fldl 96(%rsp)
fmul %st(5),%st(0)
fldl 88(%rsp)
fmulp %st(0),%st(6)
fldl 112(%rsp)
fmul %st(5),%st(0)
faddp %st(0),%st(3)
fldl 96(%rsp)
fmul %st(5),%st(0)
faddp %st(0),%st(2)
fldl 88(%rsp)
fmul %st(5),%st(0)
faddp %st(0),%st(1)
fldl 136(%rsp)
fmulp %st(0),%st(5)
fxch %st(4)
faddp %st(0),%st(5)
fldl 96(%rsp)
fmul %st(6),%st(0)
faddp %st(0),%st(2)
fldl 88(%rsp)
fmul %st(6),%st(0)
faddp %st(0),%st(1)
fldl 136(%rsp)
fmul %st(6),%st(0)
faddp %st(0),%st(4)
fldl 120(%rsp)
fmulp %st(0),%st(6)
fxch %st(5)
faddp %st(0),%st(4)
fldl 88(%rsp)
fmul %st(2),%st(0)
faddp %st(0),%st(1)
fldl 136(%rsp)
fmul %st(2),%st(0)
faddp %st(0),%st(5)
fldl 120(%rsp)
fmul %st(2),%st(0)
faddp %st(0),%st(3)
fldl 104(%rsp)
fmulp %st(0),%st(2)
fxch %st(1)
faddp %st(0),%st(3)
fxch %st(3)
fxch %st(2)
._addatmost15bytes:
cmp  $0,%rcx
je ._nomorebytes
movl $0,0(%rsp)
movl $0,4+0(%rsp)
movl $0,8+0(%rsp)
movl $0,12+0(%rsp)
leaq 0(%rsp),%rdi
rep movsb
movb   $1,0(%rdi)
movl 12+0(%rsp),%edi
movl 8+0(%rsp),%esi
movl 4+0(%rsp),%ecx
movl 0(%rsp),%r8d
movl %edi,168(%rsp)
movl %esi,160(%rsp)
movl %ecx,152(%rsp)
movl %r8d,144(%rsp)
fxch %st(3)
faddl 168(%rsp)
fsubl poly1305_amd64_doffset3(%rip)
fxch %st(2)
faddl 160(%rsp)
fsubl poly1305_amd64_doffset2(%rip)
fxch %st(1)
faddl 152(%rsp)
fsubl poly1305_amd64_doffset1(%rip)
fxch %st(3)
faddl 144(%rsp)
fsubl poly1305_amd64_doffset0(%rip)
fldl poly1305_amd64_alpha130(%rip)
fadd %st(3),%st(0)
fsubl poly1305_amd64_alpha130(%rip)
fsubr %st(0),%st(3)
fmull poly1305_amd64_scale(%rip)
fldl poly1305_amd64_alpha32(%rip)
fadd %st(2),%st(0)
fsubl poly1305_amd64_alpha32(%rip)
fsubr %st(0),%st(2)
fldl poly1305_amd64_alpha64(%rip)
fadd %st(6),%st(0)
fsubl poly1305_amd64_alpha64(%rip)
fsubr %st(0),%st(6)
fldl poly1305_amd64_alpha96(%rip)
fadd %st(5),%st(0)
fsubl poly1305_amd64_alpha96(%rip)
fsubr %st(0),%st(5)
fxch %st(4)
faddp %st(0),%st(3)
fxch %st(6)
faddp %st(0),%st(1)
fxch %st(3)
faddp %st(0),%st(5)
fxch %st(3)
faddp %st(0),%st(1)
fldl 128(%rsp)
fmul %st(3),%st(0)
fldl 112(%rsp)
fmul %st(4),%st(0)
fldl 96(%rsp)
fmul %st(5),%st(0)
fldl 88(%rsp)
fmulp %st(0),%st(6)
fldl 112(%rsp)
fmul %st(5),%st(0)
faddp %st(0),%st(3)
fldl 96(%rsp)
fmul %st(5),%st(0)
faddp %st(0),%st(2)
fldl 88(%rsp)
fmul %st(5),%st(0)
faddp %st(0),%st(1)
fldl 136(%rsp)
fmulp %st(0),%st(5)
fxch %st(4)
faddp %st(0),%st(5)
fldl 96(%rsp)
fmul %st(6),%st(0)
faddp %st(0),%st(2)
fldl 88(%rsp)
fmul %st(6),%st(0)
faddp %st(0),%st(1)
fldl 136(%rsp)
fmul %st(6),%st(0)
faddp %st(0),%st(4)
fldl 120(%rsp)
fmulp %st(0),%st(6)
fxch %st(5)
faddp %st(0),%st(4)
fldl 88(%rsp)
fmul %st(2),%st(0)
faddp %st(0),%st(1)
fldl 136(%rsp)
fmul %st(2),%st(0)
faddp %st(0),%st(5)
fldl 120(%rsp)
fmul %st(2),%st(0)
faddp %st(0),%st(3)
fldl 104(%rsp)
fmulp %st(0),%st(2)
fxch %st(1)
faddp %st(0),%st(3)
fxch %st(3)
fxch %st(2)
._nomorebytes:
fldl poly1305_amd64_alpha130(%rip)
fadd %st(4),%st(0)
fsubl poly1305_amd64_alpha130(%rip)
fsubr %st(0),%st(4)
fmull poly1305_amd64_scale(%rip)
fldl poly1305_amd64_alpha32(%rip)
fadd %st(2),%st(0)
fsubl poly1305_amd64_alpha32(%rip)
fsubr %st(0),%st(2)
fldl poly1305_amd64_alpha64(%rip)
fadd %st(4),%st(0)
fsubl poly1305_amd64_alpha64(%rip)
fsubr %st(0),%st(4)
fldl poly1305_amd64_alpha96(%rip)
fadd %st(6),%st(0)
fsubl poly1305_amd64_alpha96(%rip)
fsubr %st(0),%st(6)
fxch %st(4)
faddp %st(0),%st(3)
fxch %st(4)
faddp %st(0),%st(1)
fxch %st(4)
faddp %st(0),%st(3)
fxch %st(4)
faddp %st(0),%st(1)
fxch %st(3)
faddl poly1305_amd64_hoffset0(%rip)
fxch %st(2)
faddl poly1305_amd64_hoffset1(%rip)
fxch %st(1)
faddl poly1305_amd64_hoffset2(%rip)
fxch %st(3)
faddl poly1305_amd64_hoffset3(%rip)
fxch %st(2)
fstpl 88(%rsp)
fstpl 96(%rsp)
fxch %st(1)
fstpl 104(%rsp)
fstpl 112(%rsp)
movl 92(%rsp),%edi
and  $63,%edi
movl 100(%rsp),%esi
and  $63,%esi
movl 108(%rsp),%ecx
and  $63,%ecx
movl 116(%rsp),%r8d
and  $63,%r8d
movl 96(%rsp),%eax
add %edi,%eax
movl 104(%rsp),%edi
adc %esi,%edi
movl 112(%rsp),%esi
adc %ecx,%esi
mov  $0,%rcx
adc %r8d,%ecx
mov  $5,%r8
movl 88(%rsp),%r10d
add %r10d,%r8d
mov  $0,%r11
adc %eax,%r11d
mov  $0,%r12
adc %edi,%r12d
mov  $0,%r13
adc %esi,%r13d
mov  $-4,%r14
adc %ecx,%r14d
sar  $16,%r14d
mov  %r14,%rcx
xor  $-1,%ecx
and  %r14,%r10
and  %rcx,%r8
or   %r8,%r10
and  %r14,%rax
and  %rcx,%r11
or   %r11,%rax
and  %r14,%rdi
and  %rcx,%r12
or   %r12,%rdi
and  %r14,%rsi
and  %rcx,%r13
or   %r13,%rsi
mov  %rdx,%rdx
addl 0(%rdx),%r10d
adcl 4(%rdx),%eax
adcl 8(%rdx),%edi
adcl 12(%rdx),%esi
mov  %r9,%rdx
movl   %r10d,0(%rdx)
movl   %eax,4(%rdx)
movl   %edi,8(%rdx)
movl   %esi,12(%rdx)
movq 32(%rsp),%r11
movq 40(%rsp),%r12
movq 48(%rsp),%r13
movq 56(%rsp),%r14
movq 64(%rsp),%r15
movq 72(%rsp),%rbx
movq 80(%rsp),%rbp
add %r11,%rsp
ret
